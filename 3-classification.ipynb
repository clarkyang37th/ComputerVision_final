{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c49b4266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import copy\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49bf0774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "# import torchvision\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00cde1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "### process every xml files to be 'filename':[[xmin_room1,xmax_room1,ymin_room1,ymax_room1,label_room1],\n",
    "### [xmin_room2,xmax_room2,ymin_room2,ymax_room2,label_room2],...]\n",
    "\n",
    "directName = \"./data_1\"\n",
    "# directName = \"./\"\n",
    "script_dict = {}   ### record of each figure and each room of it\n",
    "room_dict = {}     ### labels for different room: living room, bedroom, ...\n",
    "room_count = {}\n",
    "xy_dist = []\n",
    "for file in os.listdir(directName):\n",
    "    if file.endswith(\".xml\"):\n",
    "        fileNamePre = file[:-4]\n",
    "        tree = ET.parse(os.path.join(directName, file))\n",
    "        root = tree.getroot()\n",
    "        script_dict[fileNamePre] = []\n",
    "        for item in root.findall('object'):\n",
    "            rooms = [None]*5\n",
    "            for child in item:\n",
    "                if(child.tag == 'name'):\n",
    "                    room_type = child.text\n",
    "                    room_type_digit = -1\n",
    "                    if(room_type in room_dict):\n",
    "                        room_type_digit = room_dict[room_type]\n",
    "                        room_count[room_type_digit] = room_count[room_type_digit] + 1\n",
    "                    else:\n",
    "                        room_type_digit = len(room_dict)\n",
    "                        room_dict[room_type] = room_type_digit \n",
    "                        room_count[room_type_digit] = 1\n",
    "                    rooms[4] = room_type_digit\n",
    "                elif(child.tag == 'bndbox'):\n",
    "                    for grandchild in child:\n",
    "                        if grandchild.tag=='xmin':\n",
    "                            rooms[0] = int(grandchild.text)\n",
    "                        elif grandchild.tag=='xmax':\n",
    "                            rooms[1] = int(grandchild.text)\n",
    "                        elif grandchild.tag=='ymin':\n",
    "                            rooms[2] = int(grandchild.text)\n",
    "                        elif grandchild.tag=='ymax':\n",
    "                            rooms[3] = int(grandchild.text)\n",
    "            xy_dist.append(rooms[1]-rooms[0])\n",
    "            xy_dist.append(rooms[3]-rooms[2])\n",
    "            script_dict[fileNamePre].append(rooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90c4e9cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0134b1-1': [[975, 1200, 823, 955, 0],\n",
       "  [721, 946, 824, 1092, 1],\n",
       "  [719, 1102, 1118, 1579, 2],\n",
       "  [1562, 1875, 968, 1302, 2],\n",
       "  [1134, 1532, 1107, 1575, 3],\n",
       "  [1236, 1538, 819, 1105, 4],\n",
       "  [1559, 1879, 737, 940, 5]],\n",
       " '0134b2-1': [[2062, 2428, 794, 960, 1],\n",
       "  [2055, 2431, 518, 757, 6],\n",
       "  [1238, 1606, 526, 877, 2],\n",
       "  [2057, 2431, 999, 1399, 2],\n",
       "  [1238, 2036, 904, 1391, 3],\n",
       "  [1630, 2042, 519, 885, 4]],\n",
       " '0134b2-2': [[2084, 2453, 746, 919, 1],\n",
       "  [2065, 2452, 477, 714, 6],\n",
       "  [1261, 1628, 858, 1351, 2],\n",
       "  [2087, 2451, 942, 1350, 2],\n",
       "  [1260, 1628, 473, 827, 2],\n",
       "  [1658, 2062, 475, 1350, 3],\n",
       "  [1643, 2069, 1378, 1591, 7]],\n",
       " '0134b3-1': [[1586, 1727, 667, 961, 1],\n",
       "  [1407, 1565, 660, 972, 6],\n",
       "  [1153, 1386, 661, 956, 2],\n",
       "  [1405, 1663, 1112, 1477, 2],\n",
       "  [1882, 2201, 1106, 1418, 3],\n",
       "  [1746, 2017, 662, 954, 4],\n",
       "  [2045, 2204, 662, 960, 5],\n",
       "  [1154, 1382, 977, 1411, 8]],\n",
       " '0134b3-2': [[1658, 1798, 742, 1044, 1],\n",
       "  [2111, 2275, 747, 938, 1],\n",
       "  [1475, 1633, 745, 1043, 6],\n",
       "  [1480, 1732, 1200, 1565, 2],\n",
       "  [1820, 2096, 743, 1041, 2],\n",
       "  [1953, 2280, 1064, 1362, 2],\n",
       "  [1753, 1938, 1197, 1426, 3],\n",
       "  [1228, 1458, 745, 1067, 3]]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9f39dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'storage': 0,\n",
       " 'bathroom': 1,\n",
       " 'bedroom': 2,\n",
       " 'living room': 3,\n",
       " 'dining room': 4,\n",
       " 'kitchen': 5,\n",
       " 'stairs': 6,\n",
       " 'balcony': 7,\n",
       " 'garage': 8}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "room_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a3cae552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 34, 1: 259, 2: 339, 3: 198, 4: 56, 5: 78, 6: 203, 7: 77, 8: 28, 9: 5}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "room_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f7cc3b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rooms = 0\n",
    "for key in room_count:\n",
    "    total_rooms += room_count[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dda50707",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [None]*10\n",
    "for i in range(10):\n",
    "    weights[i] = total_rooms/room_count[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "28516b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.from_numpy(np.array(weights).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c29a786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([12., 14., 20., 19.,  5.,  0.,  0.,  0.,  1.,  1.]),\n",
       " array([132. , 206.3, 280.6, 354.9, 429.2, 503.5, 577.8, 652.1, 726.4,\n",
       "        800.7, 875. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(xy_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3712962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2422b41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53f15dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_rooms_coords(directName, script_dict, resize_scale):\n",
    "#     X_cor = []\n",
    "#     Y_cor = []\n",
    "#     for file in os.listdir(directName): \n",
    "#         if file.endswith(\".xml\"):\n",
    "#             fileNamePre = file[:-4]\n",
    "#             img = cv2.imread(fileNamePre+'.png', cv2.IMREAD_GRAYSCALE)\n",
    "#             coords = script_dict[fileNamePre]\n",
    "#             for cor in coords:\n",
    "#                 img_part = img[cor[2]:cor[3],cor[0]:cor[1]]\n",
    "#                 img_part = cv2.resize(img_part, (resize_scale,resize_scale))\n",
    "#                 X_cor.append(img_part)\n",
    "#                 Y_cor.append(cor[4])\n",
    "#                 X_cor.append(np.rot90(img_part,2))\n",
    "#                 Y_cor.append(cor[4])\n",
    "#     X_cor = np.array(X_cor)\n",
    "#     Y_cor = np.array(Y_cor)\n",
    "#     return np.expand_dims(X_cor, axis=1), Y_cor    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1549c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X,Y = split_rooms_coords(directName,script_dict,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "edf446e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rooms_coords_rot(directName, script_dict, resize_scale, test_ratio):\n",
    "    X_cor = []\n",
    "    Y_cor = []\n",
    "    for file in os.listdir(directName): \n",
    "        if file.endswith(\".xml\"):\n",
    "            fileNamePre = file[:-4]\n",
    "            filePath = os.path.join(directName, fileNamePre+'.png')\n",
    "#             print(fileNamePre)\n",
    "            img = cv2.imread(filePath, cv2.IMREAD_GRAYSCALE)\n",
    "            coords = script_dict[fileNamePre]\n",
    "            for cor in coords:\n",
    "                if(cor[4]!=1 and cor[4]!=2 and cor[4]!=3 and cor[4]!=6):\n",
    "                    continue\n",
    "                img_part = img[cor[2]:cor[3],cor[0]:cor[1]]\n",
    "                img_part = cv2.resize(img_part, (resize_scale,resize_scale))\n",
    "                X_cor.append(img_part)\n",
    "                Y_cor.append(cor[4])\n",
    "                X_cor.append(np.rot90(img_part,1))  ## rotate 90 degree\n",
    "                Y_cor.append(cor[4])\n",
    "                X_cor.append(np.rot90(img_part,2))  ## rotate 180 degree\n",
    "                Y_cor.append(cor[4])\n",
    "#                 if(cor[4]!=1 and cor[4]!=2 and cor[4]!=3 and cor[4]!=6):\n",
    "#                     X_cor.append(np.rot90(img_part,3))  ## rotate 270 degree\n",
    "#                     Y_cor.append(cor[4])\n",
    "#                     X_cor.append(np.flipud(img_part))  ## updown\n",
    "#                     Y_cor.append(cor[4])\n",
    "#                     X_cor.append(np.fliplr(img_part))  ## leftright\n",
    "#                     Y_cor.append(cor[4])\n",
    "    X_cor = np.array(X_cor)\n",
    "    Y_cor = np.array(Y_cor)\n",
    "    X, y = shuffle(X_cor, Y_cor, random_state=0)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c83636a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_rooms_coords_rot(directName, script_dict, 300, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "81bdb2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2697, 300, 300) (300, 300, 300) (2697,) (300,)\n",
      "0.24273 0.027000000000000003 1.0788e-05 1.2000000000000002e-06\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "print(X_train.nbytes*1e-9, X_test.nbytes*1e-9, y_train.nbytes*1e-9, y_test.nbytes*1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a9829b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75527c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "082eb1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "momentum = 0.9\n",
    "lr = 0.01\n",
    "epochs = 10\n",
    "log_interval = 4\n",
    "nclasses = len(room_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f59e77f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "\n",
    "        self.X = torch.from_numpy(np.expand_dims(X, axis=1).astype(np.float32))\n",
    "#         self.y = torch.from_numpy(y.astype(np.float32).reshape([-1,1]))\n",
    "        self.y = torch.from_numpy(y.reshape([-1,1]).squeeze(1)).long()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "train_dataset = MyDataset(X_train, y_train)\n",
    "test_dataset = MyDataset(X_test, y_test)\n",
    "# val_dataset = MyDataset(X_path=\"validation/X.pt\", y_path=\"validation/y.pt\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "# val_loader = torch.utils.data.DataLoader(\n",
    "#     val_dataset, batch_size=batch_size, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1e62c943",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 3, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(3, 3, kernel_size=10)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(300, 100)\n",
    "        self.fc2 = nn.Linear(100, nclasses)\n",
    "        self.batchNorm1 = nn.BatchNorm2d(3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = self.batchNorm1(x)\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = self.batchNorm1(x)\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = self.batchNorm1(x)\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = self.batchNorm1(x)\n",
    "        x = x.view(-1, 300)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3bd94279",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "# criterion = nn.CrossEntropyLoss(weight = weights)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "17c4ec31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "#         loss = F.nll_loss(output, target)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "#     model.eval()\n",
    "#     true_num = 0\n",
    "#     total_num = 0\n",
    "#     with torch.no_grad():\n",
    "#         for batch_idx, (data, target) in enumerate(test_loader):\n",
    "#             output = model(data)\n",
    "#             output_labels = np.argmax(output, axis=1)\n",
    "#             true_num += (output_labels==target).sum()\n",
    "#             total_num += output_labels.shape[0]\n",
    "#     print('test accuracy:',true_num/total_num)\n",
    "#     model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "95b681a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        #data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.cross_entropy(output, target, reduction='sum').item() # sum up batch loss\n",
    "        #test_loss += F.cross_entropy(output, target, sum=True).item() # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709a74f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
